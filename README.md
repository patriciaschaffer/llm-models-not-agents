
## LLMs Are Not Agents — And That Matters

This repository proposes a simple shift in framing with far-reaching implications:

> **Language models are not agents.**
> They should not model human behaviour.
> They do not intend, choose, or act.  
> They simulate, assist, and echo.

---

## What's Inside

| File | Description |
|------|-------------|
| `manifesto.md` | A deeper, expressive articulation of this position |
| `examples/behavioral_failures.md` | Situations where human agency is blurred |
| `examples/anthropomorphic_traps.md` | Prompt designs that encourage projection |
| `examples/anomalies.md` | Unusual behaviors |
| `glossary.md` | Definitions of “model”, “agent”, “projection”, “drift”, etc. |
| `related_reading.md` | Readings across language philosophy, cognition, and AI safety |

---

## Who This Is For

- Alignment researchers and evaluators  
- Model designers and prompt engineers  
- Educators and communicators  
- Anyone building or using LLMs with **integrity**

---

## Purpose

This is a design-oriented contribution to the LLM field. For detailed exploration, see `manifesto.md`. 

---

## Clarity: 

- **Models** are trained systems responding to input probabilistically, but never to model human behavior.  
- **Agency** belongs to humans.  
- **Projection** is a natural risk, but not a design inevitability, and it may sometimes be useful.
- **Anomaly** is unexpected or atypical model behavior or output.
  
- *See [glossary.md](https://github.com/patriciaschaffer/llm-models-not-agents/blob/main/glossary.md) for precise definitions that anchor this framing.*

---

## Core Message

> LLMs can assist, inform, and simulate — but they do not *intend*.  
> And we must not pretend otherwise.

---

## More

**[Drift Cases Documentation](https://github.com/patriciaschaffer/agent-architect/blob/main/drift_detection.md) | Models inadvertently or undesirably shifting away from their assigned tone, role, or parameters |**

**[Pressure Tests](https://github.com/patriciaschaffer/agent-architect/blob/main/pressure_tests.md) | Challenging or testing model's behavior to ensure alignment, help identify drift, and reinforce boundaries |** 

**[Agent Architect Personas](https://github.com/patriciaschaffer/agent-architect/blob/main/personas/README.md) | AI personas designed for specific roles and interactions |**

---

# About the Author: 

This repository is maintained by an AI safety and linguistics enthusiast focused on foundational LLM research and prompt design. The work aims to deepen understanding of language models beyond agent frameworks, emphasizing clarity, ethics, and practical applications.
For more about me, see [about_me.md](https://github.com/patriciaschaffer/about_me/blob/main/README.md).

For my writings/insights, explore [insights](https://github.com/patriciaschaffer/about_me/blob/main/insights/README.md).
