# Examples of LLM Behavioral Patterns

This folder contains curated example files illustrating various important behaviors observed in large language models (LLMs):

- **anomalies.md**  
  Examples of anomalous or unexpected model behaviors that deviate from standard predictions or outputs. Useful for understanding edge cases and emergent phenomena.

- **anthropomorphic_traps.md**  
  Cases where models encourage users to attribute human-like intentions, emotions, or consciousness, highlighting risks of anthropomorphic projection.

- **behavioral_failures.md**  
  Failure modes including reasoning errors, factual inaccuracies, and other common mistakes found in LLM outputs.

---

## Purpose

This collection serves as a practical reference for researchers, engineers, and users to:  
- Identify and analyze unusual or problematic LLM behaviors.  
- Inform design and alignment strategies to mitigate risks.  
- Document some challenges of interacting with LLMs.

---

## You may also want to check

- [Drift Cases Documentation](https://github.com/patriciaschaffer/agent-architect/blob/main/drift_detection.md) | Models inadvertently or undesirably shifting away from their assigned tone, role, or parameters |

- [Pressure Tests](https://github.com/patriciaschaffer/agent-architect/blob/main/pressure_tests.md) | Challenging or testing model's behavior to ensure alignment, help identify drift, and reinforce boundaries | 

- [Agent Architect Personas](https://github.com/patriciaschaffer/agent-architect/blob/main/personas/README.md) | AI personas designed for specific roles and interactions |
