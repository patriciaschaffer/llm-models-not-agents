# Manifesto: LLMs Are Models, Not Agents

Large language models are extraordinary tools.  
They simulate reasoning, express personality, and generate humanlike language with remarkable fluency. But no matter how coherent or compelling their output, one truth remains:

> They do not intend.  
> They do not act.  
> They are not agents.

This manifesto is a reminder — and a design statement.

---

## The Core Distinction

**Models** are probabilistic systems trained on vast corpora. They predict the next word, token, or phrase based on learned patterns.  
They do not *decide*. They do not *choose*. They do not possess goals.

**Agency**, in contrast, implies intent. It implies initiative, purpose, memory of self, a direction acted upon.  
This belongs to humans — not to stochastic parrot systems, no matter how sophisticated.

Yet, as LLMs grow more naturalistic in tone and fluid in output, they invite projection. They feel agentic — not because they *are*, but because they reflect our language, emotions, and mental models.

---

## Why This Framing Matters

The language we use shapes the systems we design.  
Calling models “agents” has consequences:

- It **misleads users** into over-trusting simulations
- It **confuses accountability**, especially in high-stakes interactions
- It **overhypes capabilities**, reducing our vigilance as designers
- It **shifts moral weight** from developers and deployers to “the machine”

We should admire what LLMs can do — but never pretend they’re something they’re not.

---

## The Role of Design

LLMs don’t label themselves.  
Humans write the prompts. Humans craft the personalities. Humans decide what “mode” a model enters — helper, friend, analyst, artist.

That’s why it’s our responsibility to build with:
- **Transparency** over illusion  
- **Precision** over metaphor  
- **Ethical clarity** over emotional projection

Design isn’t just visual or technical — it’s conceptual. The metaphors we choose become the architectures we build.

---

## My Position

This repo and the projects to follow are grounded in this belief:

> LLMs can simulate agency — but that does not grant them intention.  
> It is up to us, as designers, researchers, and users, to preserve the boundary between simulation and selfhood.

I do not reject personality in models. I believe in crafting *rich, coherent, even poetic* interfaces.  
But I hold firm to this line:

**LLMs are models. Humans remain the agents.**

Let’s build accordingly.

---

*Authored by Patricia, July 2025.  
Content shaped using LLM tooling UNDER HUMAN DIRECTION.*
